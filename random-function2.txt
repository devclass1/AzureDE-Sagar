# Pyspark random sample through
# sample function with fraction and seed as arguments

# Import the SparkSession library
from pyspark.sql import SparkSession

# Create a spark session using getOrCreate() function
spark_session = SparkSession.builder.getOrCreate()

# Read the CSV file
data_frame=csv_file = spark_session.read.csv('dbfs:/FileStore/tables/student_data1.csv',
							sep = ',', inferSchema = True, header = True)

# Extract random sample through sample function
# using seed and fraction as arguments
data_frame.sample(0.4,26).collect()

# Again extract random sample through sample function using seed and
# fraction as arguments to check if we get same output each time
data_frame.sample(0.4,26).collect()
